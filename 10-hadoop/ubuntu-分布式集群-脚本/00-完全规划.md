## 操作系统：ubuntu-2204



## 主机规划





| 主机名 | hadoopnn     | hadooprm        | hadoop2nn         |
| ------ | ------------ | --------------- | ----------------- |
| IP     | 172.31.3.201 | 172.31.3.202    | 172.31.3.203      |
| HDFS   | NameNode     |                 | SecondaryNameNode |
| YARN   |              | ResourceManager |                   |
|        |              |                 |                   |



| 主机名 | hadoop101    | hadoop102    | hadoop103    | ...         | hadoopxxx    |
| ------ | ------------ | ------------ | ------------ | ----------- | ------------ |
| IP     | 172.31.3.101 | 172.31.3.102 | 172.31.3.103 | ...         | 172.31.3.xxx |
| HDFS   | DataNode     | DataNode     | DataNode     | DataNode    | DataNode     |
| YARN   | NodeManager  | NodeManager  | NodeManager  | NodeManager | NodeManager  |



## sshpass 命令安装

> 后面需要用到该命令，所以提前安装，在每一台机器上面安装。
>
> ```shell
> sudo apt-get update
> sudo apt-get install sshpass
> ```
>
> 

## 创建一个普通用户(假如用户名为：`hdp`)

> 为每一台节点实例，都创建一个相同的用户，密码也相同
>
> ```shell
> # 添加用户命令，并按提示输入密码，后面的就全部默认直接回车即可
> adduser hdp
> ```
>
> ```txt
> root@iZwz9882fglpfm76m117psZ:~# adduser hdp
> Adding user `hdp' ...
> Adding new group `hdp' (1000) ...
> Adding new user `hdp' (1000) with group `hdp' ...
> Creating home directory `/home/hdp' ...
> Copying files from `/etc/skel' ...
> New password: 
> Retype new password: 
> passwd: password updated successfully
> Changing the user information for hdp
> Enter the new value, or press ENTER for the default
> 	Full Name []: 
> 	Room Number []: 
> 	Work Phone []: 
> 	Home Phone []: 
> 	Other []: 
> Is the information correct? [Y/n] 
> root@iZwz9882fglpfm76m117psZ:~# 
> ```
>
> > 添加sudo 权限
>
> ```shell
> echo "hdp ALL=(ALL:ALL) ALL" > /etc/sudoers.d/hdp
> ```
>
> 



## 切换到用户hdp

> 后续的所有操作都只用hdp 即可。
>
> 在这之后所有的操作都换成用户：`hdp`



## 准备安装包

> 将JDK、HADOOP、FLINK 的安装包放到 `~/software` 目录 
>
> ```shell
> mkdir ~/software
> ```





## 修改配置shell 文件所需参数

> install.sh
>
> ```shell
> chmod +x install.sh
> ```
>
> 

## 免密登录

> 脚本执行完成之后，按照提示，配置ssh 免密登录
>
> 只需要在有提示的机器上面执行即可



### 首次运行需要格式化 NameNode

> 注意：只需要格式化NameNode 所在的那台机器实例
>
> ```shell
> hdfs namenode -format
> ```
>
> 初始化完成会多出一个data 目录(存数据的目录) 以及log 目录
>
> 如果要重新格式化，则需要将 data 和log 目录删除之后再执行，否则会报错

## 启动

### 启动HDFS

> 注意：只需要在hadoopnn 上面启动即可
>

### 停止HDFS

> $HADOOP_HOME/sbin/stop-dfs.sh

### 启动(YARN)

>  ResourceManager

> 规划在hadooprm 上面，那么就需要到对应的机器 实例去运行启动脚本
>
> $HADOOP_HOME/sbin/start-yarn.sh

### 停止YARN

> $HADOOP_HOME/sbin/stop-yarn.sh

### web 页面

- HDFS 提供的NameNode页面

  > http://${hadoopnn}:9870
  >
  > 查看在HDFS 上存储的数据信息

- YARN 提供的ResourceManager页面

  > http://${hadooprm}:8088
  >
  > 查看YARN 上运行的Job 信息