# 两个Flume 服务器的配置，且两个都是一样的，同时有在线(Kafka)处理sink 以及离线(HDFS)处理sink
# 配置Agent
a1.sources = r1
a1.sinks = k1 k2
a1.channels = c1 c2

# 声明Source
#       接收数据源为avro 序列化数据
a1.sources.r1.type = avro
a1.sources.r1.bind = 0.0.0.0
a1.sources.r1.port = 44444

# 声明Sink
#       将数据存储到HDFS
a1.sinks.k1.type = hdfs
#       这里使用到了时间戳，那么在event 中必须要有 timestamp 属性
#       时间戳的格式在官网的 "Flume Sinks" -->  "HDFS Sink"  标签下
# a1.sinks.k1.hdfs.path = hdfs://Hadoop01:9000/flux/reportTime=%Y-%m-%d_%H%M%S
#       完全分布式的Hadoop 集群地址 ns 的hadoop 与flume 在同一台机器上面可以通过环境变量知道这个ns 
#       如果hadoop 与flume 不在同一台机器上，那么需要把hadoop 的配置文件拷贝到flume 的conf 目录下面
# a1.sinks.k1.hdfs.path = hdfs://ns:9000/flux/reportTime=%Y-%m-%d
a1.sinks.k1.hdfs.path = hdfs://Hadoop01:9000/flux/reportTime=%Y-%m-%d
a1.sinks.k1.hdfs.rollInterval = 30
a1.sinks.k1.hdfs.rollSize = 0
a1.sinks.k1.hdfs.rollCount = 0
#       数据类型的存储形式以源数据的形式，不做序列化处理
a1.sinks.k1.hdfs.fileType = DataStream
#       对时间戳按以下时区处理。即：东八区
#       默认情况是按运行flume 所在计算机的本地时区处理
a1.sinks.k1.hdfs.timeZone = GMT+8

#       配置sink 下游到kafka
#           在线处理数据
a1.sinks.k2.type = org.apache.flume.sink.kafka.KafkaSink
#           下面这句是从官方网上拷贝来的，但是有问题
#           问题出在哪里还不知道。
# a1.sinks.k2.kafka.topic = FluxTopic
a1.sinks.k2.topic = FluxTopic
#           kafka 的集群地址
a1.sinks.k2.brokerList = Hadoop01:9092,Hadoop02:9092,Hadoop03:9092




# 声明Channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.channels.c2.type = memory
a1.channels.c2.capacity = 1000
a1.channels.c2.transactionCapacity = 100

# 绑定关系
a1.sources.r1.channels = c1 c2
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c2



