


- ## 内部表
    - > 内部表可以从本地加载文件，然后上传到hive 的数据库的所在HDFS 的位置
    - > 内部表可以从HDFS 加载文件，然后也要上传到hive 的数据库所在的HDFS 的位置
    - > 也就是说内部表可以从任何地方加载数据文件，但是这些加载的数据都会被上传到hive 在HDFS 上的某个位置上面。

- ## 内部表与外部表区别
    - > 内部表
        > - 数据是存放在默认的一个HDFS路径下。插入数据时添加，删除表时清除。
        > - 数据和元数据都是由hive 来管理。
    - > 外部表
        > - 数据是由用户自己存储在一个HDFS 目录。表只是关联到此目录下的文件数据。
        > - 数据是由用户来管理且存放在HDFS 上面。元数据是由hive 来管理。

- ## 分区
    - > ### 分区列
        > - 分区列只有在创建表的时候指定，以后无论怎么样分区都被固定了。
        >> - 所以`ALTER TABLE xxx ADD PARTITION` 添加的只是值，而不是分区列。
    - > ### 单分区
        - > 分区也是一个列
    - > ### 双分区(多分区)
    - > ### 分区修复
        > - 使用场景
        >> - 分区是作为元数据存储在MySQL 中的，当HDFS 路径中包含多级目录，同时存在 分区列时，可以创建外部表使用，但是分区的元数据没有在MYSQL 中存在，查不到数据。
        > - 如果创建表的时候指定了分区。HDFS 中的数据是在创建表之后添加的。那么这些数据中的分区数据在hive 中是不能被识别的，这个时候就需要用到分区修复功能了。
        > - `MSCK REPAIR TABL psn;`
        > - 它主要是去查找，当前增加了哪些分区，并将这些分区作为元数据存储起来。

- ## 动态分区
    - > 注意: 动态分区对应的一定是离线数据。实时数据无法做动态分区
    - > 开启动态分区需要几个参数
        > - `hive.exec.dynamic.partition=true` 默认就是`true`
        > - `hive.exec.dynamic.partition.mode=nostrict` 默认是 `strict`
        >> - `strict` 是指至少有一个分区列是静态分区
    - > 相关参数
        > - `hive.exec.max.dynamic.partitions.pernode`
        >> - 每一个执行mr 节点上，允许创建的动态分区的最大数据(100)
        > - `hive.exec.max.dynamic.partitions`
        >> - 所有执行mr节点上，允许创建的所有动态分区的最磊数据(1000)
        > - `hive.exec.max.created.fields`
        >> - 所有的mr job 允许创建的文件的最大数量(100000)
        >> - 100000 个打开文件大概对应1GB 内存资源


- ## 分桶
    - > 参数    
        > - 需要开启支持分桶的参数
        >> - `hive.enforce.bucketing=true;` 默认是`false`;
    - > 语法
        > - tablesample(bucket x out of y)
        >> - x: 从哪个桶取数据
        >> - Y: 桶的个数的整数倍，或者整除










