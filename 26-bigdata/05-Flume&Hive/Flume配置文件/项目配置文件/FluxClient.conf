# 配置Agent

a1.sources = r1
a1.sinks = k1 k2
a1.channels = c1

# 配置Source
#     接收avro 协议序死化的数据
a1.sources.r1.type = avro
a1.sources.r1.bind = 0.0.0.0
a1.sources.r1.port = 44444

#     配置拦截器，从数据源中提取时间戳并将时间戳添加到header 中
#     以便后面以日期的形式存储到HDFS 中
#     regex_extractor: 匹配正则，将匹配到的分组数据以Key-Value的形式添加到Headers 中
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = regex_extractor
a1.sources.r1.interceptors.i1.regex = ^(?:[^\\|]*\\|){14}\\d+_\\d+_(\\d+)\\|.*$
a1.sources.r1.interceptors.i1.serializers = s1
#          timestamp 是后面需要的一个Key 所以这里不能乱写
a1.sources.r1.interceptors.i1.serializers.s1.name = timestamp


# 配置Sink
#       下游发到Hadoop01
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = Hadoop01
a1.sinks.k1.port = 44444

#       下游发到Hadoop02
a1.sinks.k2.type = avro
a1.sinks.k2.hostname = Hadoop02
a1.sinks.k2.port = 44444

#       sink 分组 负载均衡
a1.sinkgroups = g1
a1.sinkgroups.g1.sinks = k1 k2
#           一个channel 往这个组里面的全部sink 下发数据，使用负载均衡的方式分发数据
a1.sinkgroups.g1.processor.type = load_balance
#           节点失效，则将节点从sinkgroup中移除一段时间
a1.sinkgroups.g1.processor.backoff = true
#           随机模式
a1.sinkgroups.g1.processor.selector = random

# 配置Channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# 绑定Channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c1

