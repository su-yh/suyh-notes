<configuration>
    <!--执行hdfs的nameservice为ns,和core-site.xml 中的fs.defaultFS的值保持一致-->
    <property>
        <name>dfs.nameservices</name>
        <value>ns</value>
    </property>
    <!--ns下有两个NameNode,分别是nn1,nn2-->
    <property>
        <name>dfs.ha.namenodes.ns</name>
        <value>nn1,nn2</value>
    </property>
    <!--nn1(NameNode1)的RPC通信地址-->
    <property>
        <name>dfs.namenode.rpc-address.ns.nn1</name>
        <value>Hadoop01:9000</value>
    </property>
    <!--nn1(NameNode1)的http通信地址-->
    <property>
        <name>dfs.namenode.http-address.ns.nn1</name>
        <value>Hadoop01:50070</value>
    </property>
    <!--nn2(NameNode2)的RPC通信地址-->
    <property>
        <name>dfs.namenode.rpc-address.ns.nn2</name>
        <value>Hadoop02:9000</value>
    </property>
    <!--nn2(NameNode2)的http通信地址-->
    <property>
        <name>dfs.namenode.http-address.ns.nn2</name>
        <value>Hadoop02:50070</value>
    </property>
    <!--指定namenode的元数据在JournalNode上的存放位置,这样，namenode2可以从jn集群里获取最新的namenode的信息，达到热备的效果-->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://Hadoop01:8485;Hadoop02:8485;Hadoop03:8485/ns</value>
    </property>
    <!--指定JournalNode存放数据的位置-->
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/root/software/hadoop-2.7.1/journal</value>
    </property>
    <!--开启namenode故障时自动切换-->
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>
    <!--配置切换的实现方式-->
    <property>
        <name>dfs.client.failover.proxy.provider.ns</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <!--配置隔离机制-->
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>sshfence</value>
    </property>
    <!--配置隔离机制的ssh登录秘钥所在的位置-->
    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/root/.ssh/id_rsa</value>
    </property>
    
    <!--配置namenode数据存放的位置,可以不配置，如果不配置，默认用的是core-site.xml里配置的hadoop.tmp.dir的路径-->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///root/software/hadoop-2.7.1/tmp/hdfs/namenode</value>
    </property>
    <!--配置datanode数据存放的位置,可以不配置，如果不配置，默认用的是
            core-site.xml里配置的hadoop.tmp.dir的路径-->
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///root/software/hadoop-2.7.1/tmp/hdfs/datanode</value>
    </property>
    
    <!--配置block副本数量-->
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <!--设置hdfs的操作权限，false表示任何用户都可以在hdfs上操作文件-->
    <property>
        <name>dfs.permissions</name>
        <value>false</value>
    </property>
 
</configuration>
